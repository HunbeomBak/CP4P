{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 99% with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# simple CNN\n",
    "\n",
    "Input layer - Convolutional layer1 - Pooling layer1 - Convolutional layer2 - Pooling layer2 - Fully conneted layer 이렇게 쌓아보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv layer 1\n",
    "\n",
    "인풋부터 정해주자\n",
    "\n",
    "우리가 사용할 MNIST 데이터는 28 X 28에 색이 Black/White뿐이여서 28 X 28 X 1이 된다\n",
    "\n",
    "따라서 이미지 입력으로 넣어주기 위해 X를 reshape 해줘야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X= tf.placeholder(tf.float32, [None,784])\n",
    "X_img=tf.reshape(X, [-1,28,28,1])\n",
    "Y= tf.placeholder(tf.float32, [None,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 첫번째 conv 레이어를 만들어보자\n",
    "\n",
    "이미지의 모양은 (?, 28,28, 1)이다.\n",
    "\n",
    "필터의 모양은 우리가 정해줄 수 있는데 3X3 필터로 하고 색은 1개로 32개의 필터를 사용하자 (3,3,1,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1=tf.Variable(tf.random_normal([3,3,1,32],stddev=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 conv레이러를 통과시켜주자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d: (?, 28, 28, 32)\n"
     ]
    }
   ],
   "source": [
    "L1= tf.nn.conv2d(X_img,W1,strides=[1,1,1,1],padding='SAME')\n",
    "\n",
    "print('conv2d:',L1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stride는 1X1로 하고 padding까지 적용해주면 모양은 (?,28,28,32)일 것이다.\n",
    "\n",
    "단순히 통과만 시키지 말고 활성화함수도 적용시키자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relu: (?, 28, 28, 32)\n"
     ]
    }
   ],
   "source": [
    "L1=tf.nn.relu(L1)\n",
    "\n",
    "print('Relu:',L1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max-pooling도 통과시켜주면 첫번째 레이어가 끝난다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 14, 14, 32)\n"
     ]
    }
   ],
   "source": [
    "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "print(L1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스트라이드 2X2 이므로 크기는 (?, 28, 28, 32)에서 절반으로 줄어든 (?, 14, 14, 32)가 될것이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Conv layer 2\n",
    "\n",
    "두번째 레이어를 통과시키자. \n",
    "\n",
    "이때 들어오는 값의 크기는 Max-pooling을 통과하고 나온 (?, 14, 14, 32)가 될것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W2=tf.Variable(tf.random_normal([3,3,32,64],stddev=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "들어갈때 32개의 이미지 이므로 32는 꼭 유지 해야한다!! 3X3의 필터가 64개 생겼다 얏호 \n",
    "\n",
    "이하 과정은 첫번째 레이어와 똑같다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 14, 14, 64)\n"
     ]
    }
   ],
   "source": [
    "L2=tf.nn.conv2d(L1,W2,strides=[1,1,1,1],padding='SAME')\n",
    "print(L2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 14, 14, 64)\n"
     ]
    }
   ],
   "source": [
    "L2=tf.nn.relu(L2)\n",
    "\n",
    "print(L2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 7, 7, 64)\n"
     ]
    }
   ],
   "source": [
    "L2= tf.nn.max_pool(L2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "print(L2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully-connected 통과시키기 전에 입체적으로 되어있는 모양을 펼쳐줘야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 3136)\n"
     ]
    }
   ],
   "source": [
    "L2= tf.reshape(L2,[-1,7*7*64])\n",
    "\n",
    "print(L2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FC layer\n",
    "\n",
    "받은 7X7X64를 10개(숫자들의 원핫인코딩: 0~9)으로 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3=tf.get_variable(\"W3\",shape=[7*7*64,10],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b=tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "hypothesis = tf.matmul(L2,W3)+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 만들었으므로 loss 함수와 학습시킬 준비를 하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "optimizer =tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 시키기지 전에 변수를 초기화 시키자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 가즈ㅏㅏㅏㅏ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning starts. It takes sometimes\n",
      "Epoch: 0001 cost= 0.333181420\n",
      "Epoch: 0002 cost= 0.095014806\n",
      "Epoch: 0003 cost= 0.069303063\n",
      "Epoch: 0004 cost= 0.054589429\n",
      "Epoch: 0005 cost= 0.047473145\n",
      "Epoch: 0006 cost= 0.040631942\n",
      "Epoch: 0007 cost= 0.035344094\n",
      "Epoch: 0008 cost= 0.030989985\n",
      "Epoch: 0009 cost= 0.026986451\n",
      "Epoch: 0010 cost= 0.023341807\n",
      "Epoch: 0011 cost= 0.020987764\n",
      "Epoch: 0012 cost= 0.018911196\n",
      "Epoch: 0013 cost= 0.016056114\n",
      "Epoch: 0014 cost= 0.015173341\n",
      "Epoch: 0015 cost= 0.012457287\n",
      "Learning finish\n"
     ]
    }
   ],
   "source": [
    "print('Learning starts. It takes sometimes')\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost=0\n",
    "    total_batch= int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys=mnist.train.next_batch(batch_size)\n",
    "        feed_dict={X:batch_xs,Y:batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer],feed_dict=feed_dict)\n",
    "        avg_cost += c/ total_batch\n",
    "    print('Epoch:','%04d'%(epoch+1),'cost=','{:.9f}'.format(avg_cost))\n",
    "print('Learning finish')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 완료 했다면 우리가 만든 모델을 시험해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9901\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(hypothesis,1),tf.argmax(Y,1)) # 예측값과 실제 값이 맞으면 1, 아니면 0\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:',sess.run(accuracy,feed_dict={X:mnist.test.images, Y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 세트에서 하나 갖고와서 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [6]\n",
      "Prediction:  [6]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2339e568780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고사이트\n",
    "1. https://github.com/hunkim/DeepLearningZeroToAll/blob/master/lab-11-1-mnist_cnn.py\n",
    "2. https://www.youtube.com/watch?v=pQ9Y9ZagZBk&list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm&index=39"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
